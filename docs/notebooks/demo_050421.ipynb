{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4cb8c71",
   "metadata": {},
   "source": [
    "# Transcriptomic Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0917974",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import transcriptomic_clustering as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d25bde3",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "transcriptomic_clustering functions operate on Annotation Data, from part of scanpy/anndata. This supports both dense sparse matrices, and additional .['obs'], .['obsm'] and .['var'], [.varm] fields for storing information about the observations (cells) and variables (genes). Data is stored as an HDF5 file, allowing for both in-memory and file-backed operations. For more information, see https://anndata.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "substantial-province",
   "metadata": {},
   "source": [
    "<img src=\"https://falexwolf.de/img/scanpy/anndata.svg\" width=\"480\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is load into memory. Add 'r' for reading and 'r+' for modifying filebacked data\n",
    "tasic_adata = sc.read_h5ad('./data/tasic2016counts_csr.h5ad', backed='r')\n",
    "print(tasic_adata)\n",
    "print(tasic_adata.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a803c0",
   "metadata": {},
   "source": [
    "## Running the Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911efc52",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "To start, we normalize the expression matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_adata = tc.normalize(tasic_adata, copy_to='./data/normalized2.h5ad')\n",
    "normalized_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98dc08d",
   "metadata": {},
   "source": [
    "### Select Highly Variable Genes\n",
    "\n",
    "We extract highly variable genes (HVGs) to further reduce the dimensionality of the dataset and include only the most informative genes. HVGs will be used for the following dimensionality reduction and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48632772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute means and variances:\n",
    "means, variances, gene_mask = tc.means_vars_genes(adata=normalized_adata)\n",
    "\n",
    "# Find highly variable genes:\n",
    "tc.highly_variable_genes(adata=normalized_adata, \n",
    "                         means=means, variances=variances, \n",
    "                         gene_mask=gene_mask, max_genes=3000)\n",
    "normalized_adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ab8cc0",
   "metadata": {},
   "source": [
    "### PCA analysis\n",
    "Now we can do principal component analysis on a subset of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b30d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA on 1000 random cells and highly variable genes\n",
    "(components, explained_variance_ratio, explained_variance) = \\\n",
    "    tc.pca(normalized_adata, cell_select=1000, use_highly_variable=True, svd_solver='arpack')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf66e60",
   "metadata": {},
   "source": [
    "## General API patterns\n",
    "### Appending to AnnData objects\n",
    "Many functions in the transcriptomic package calculate features of the data. By default, they will return the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137c47e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = sc.read_h5ad('./data/tasic2016counts_csr.h5ad')\n",
    "hvg_df = tc.highly_variable_genes(adata, \n",
    "                         means=means, \n",
    "                         variances=variances, \n",
    "                         gene_mask=gene_mask, \n",
    "                         max_genes=3000, \n",
    "                         annotate=False)\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb416f",
   "metadata": {},
   "source": [
    "However, some functions allow you to add the data to the AnnData object instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d35da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.highly_variable_genes(adata, \n",
    "                         means=means, \n",
    "                         variances=variances, \n",
    "                         gene_mask=gene_mask, \n",
    "                         max_genes=3000, \n",
    "                         annotate=True)\n",
    "\n",
    "adata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fbd6c9",
   "metadata": {},
   "source": [
    "### Modifying AnnData in Place or Making a Copy\n",
    "A function that modifies AnnData will by default make a copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d382c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default will create a new object:\n",
    "tasic_adata_inmemory = sc.read_h5ad('./data/tasic2016counts_csr.h5ad')\n",
    "normalized_adata = tc.normalize(tasic_adata_inmemory)\n",
    "print(normalized_adata is tasic_adata_inmemory) # False: different objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827bdf30",
   "metadata": {},
   "source": [
    "But passing `inplace=True` will overwrite instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d98b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But can also modify inplace:\n",
    "normalized_adata = tc.normalize(tasic_adata_inmemory, inplace=True)\n",
    "print(normalized_adata is tasic_adata_inmemory) # True: same  objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220d850",
   "metadata": {},
   "source": [
    "### Managing Memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b028ba",
   "metadata": {},
   "source": [
    "#### Available Memory and Setting Memory Limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1305774",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.memory.get_available_system_memory_GB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c265f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.memory.set_memory_limit(percent_current_available=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.memory.set_memory_limit(GB=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ae183",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.memory.get_available_memory_GB()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72925a91",
   "metadata": {},
   "source": [
    "#### Chunked Processing\n",
    "By default, chunked processing is turned-off, and tc won't do any memory management for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0238d581",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_adata_backed = tc.normalize(tasic_adata, copy_to='./data/normalized3.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a761725f",
   "metadata": {},
   "source": [
    "But setting `tc.memory.allow_chunking = True`, you can enable automatic chunked processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc.memory.allow_chunking=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-venue",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_adata_backed = tc.normalize(tasic_adata, copy_to='./data/normalized4.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-journalist",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_adata_backed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized2_adata_backed = tc.normalize(tasic_adata, copy_to='./data/normalized14.h5ad',chunk_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized2_adata_backed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-travel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
